Great question! Let's walk through how to export Lambda function output to a CSV file using Python.


---

✅ Step-by-Step Guide

🎯 Problem:

You have a Python AWS Lambda function that generates some output (e.g., list of dictionaries), and you want to save it as a CSV file.


---

🔹 Example Use Case:

Let's say your Lambda function prints this output:

[
    {"name": "Alice", "age": 30},
    {"name": "Bob", "age": 25},
    {"name": "Charlie", "age": 35}
]

You want this in a file like:

name,age
Alice,30
Bob,25
Charlie,35


---

🔹 Option 1: Save CSV in /tmp/ inside Lambda (temporary storage)

AWS Lambda allows writing files to /tmp/ directory (up to 512 MB).

✅ Full Working Example:

import csv

def lambda_handler(event, context):
    data = [
        {"name": "Alice", "age": 30},
        {"name": "Bob", "age": 25},
        {"name": "Charlie", "age": 35}
    ]

    csv_file_path = "/tmp/output.csv"

    # Writing to CSV
    with open(csv_file_path, mode='w', newline='') as csvfile:
        fieldnames = data[0].keys()  # ['name', 'age']
        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)

        writer.writeheader()
        writer.writerows(data)

    print(f"CSV written to: {csv_file_path}")
    return {"statusCode": 200, "body": f"CSV file created at {csv_file_path}"}

🟢 This writes the CSV file to /tmp/output.csv in Lambda.

❗ But this file is temporary and goes away after execution ends.


---

🔹 Option 2: Upload CSV to S3 Bucket (Recommended)

You can upload the CSV file to an S3 bucket, so it's persistent.

✅ Requirements:

IAM Role for Lambda with permission: s3:PutObject

An existing S3 bucket, e.g., my-output-bucket


✅ Example Code:

import csv
import boto3

s3 = boto3.client('s3')

def lambda_handler(event, context):
    data = [
        {"name": "Alice", "age": 30},
        {"name": "Bob", "age": 25},
        {"name": "Charlie", "age": 35}
    ]

    # Step 1: Write to /tmp/output.csv
    file_path = "/tmp/output.csv"
    with open(file_path, mode='w', newline='') as csvfile:
        fieldnames = data[0].keys()
        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
        writer.writeheader()
        writer.writerows(data)

    # Step 2: Upload to S3
    bucket_name = "my-output-bucket"
    object_key = "lambda-results/output.csv"

    s3.upload_file(file_path, bucket_name, object_key)

    return {
        "statusCode": 200,
        "body": f"CSV uploaded to s3://{bucket_name}/{object_key}"
    }

🟢 Result: CSV file is uploaded to your S3 bucket and is available to download/view.


---

🔐 IAM Permissions Required

Your Lambda's execution role should have this policy:

{
  "Effect": "Allow",
  "Action": ["s3:PutObject"],
  "Resource": "arn:aws:s3:::my-output-bucket/*"
}

Replace my-output-bucket with your actual bucket name.


---

✅ Summary

Method	Description	Persistent?

/tmp/	Temporary file inside Lambda	❌ No
Upload to S3	Stores CSV in S3 bucket	✅ Yes



---

Would you like me to:

Help you generate the output dynamically?

Help you set the S3 bucket and permissions?

Show you how to read this CSV back from S3?


Let me know what part you'd like to build next.

